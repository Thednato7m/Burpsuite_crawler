#!/usr/bin/env python3
"""
Burp Suite State File Vulnerability Analyzer
Analyzes Burp Suite state files and identifies potential vulnerabilities
Supports both XML exports and binary .burp project files
"""

import xml.etree.ElementTree as ET
import base64
import re
import sys
import sqlite3
import os
import tempfile
import gzip
from urllib.parse import urlparse, parse_qs
from typing import List, Dict, Set
import json


class BurpVulnerabilityAnalyzer:
    def __init__(self, state_file_path: str, min_confidence: str = "Low"):
        self.state_file_path = state_file_path
        self.vulnerabilities = []
        self.urls_analyzed = set()
        self.min_confidence = min_confidence  # Low, Medium, High
        self.false_positive_count = 0
        
        # Define confidence thresholds
        self.confidence_levels = {"Low": 0, "Medium": 1, "High": 2, "Certain": 3}
        
        # False positive indicators (common in legitimate code/data)
        self.false_positive_patterns = {
            'javascript_libraries': [
                r'jquery.*\.js',
                r'angular.*\.js',
                r'react.*\.js',
                r'vue.*\.js',
                r'bootstrap.*\.js',
                r'webpack',
                r'node_modules',
            ],
            'test_data': [
                r'test@example\.com',
                r'test@test\.com',
                r'user@example\.com',
                r'admin@localhost',
                r'1234-5678-9012-3456',  # Test credit card
                r'test_password',
                r'example_password',
            ],
            'documentation': [
                r'documentation',
                r'swagger',
                r'api-docs',
                r'/docs/',
            ],
            'common_words': [
                r'\bpassword\s*:\s*\*+',  # Masked passwords
                r'password\s*field',
                r'password\s*input',
                r'email\s*field',
            ]
        }
        
        # Vulnerability patterns with confidence scores
        self.sql_injection_patterns = [
            (r"error in your SQL syntax", "High"),
            (r"mysql_fetch_array\(\)", "High"),
            (r"ORA-\d{5}", "High"),
            (r"PostgreSQL.*ERROR", "High"),
            (r"Warning.*mysql_", "Medium"),
            (r"valid MySQL result", "Medium"),
            (r"MySqlClient\.", "Medium"),
            (r"SQLServer JDBC Driver", "Medium"),
            (r"SQLException", "Low"),
            (r"ODBC SQL Server Driver", "Medium"),
        ]
        
        self.xss_patterns = [
            (r"<script[^>]*>alert\(", "High"),  # Alert in script tag
            (r"javascript:alert\(", "High"),
            (r"onerror\s*=\s*['\"]?alert", "High"),
            (r"<script[^>]*>.*?</script>", "Low"),  # Generic script (many false positives)
            (r"javascript:", "Low"),
            (r"onerror\s*=", "Low"),
            (r"onload\s*=", "Low"),
            (r"onclick\s*=", "Low"),
        ]
        
        self.path_traversal_patterns = [
            (r"\.\./\.\./\.\./", "High"),  # Multiple levels
            (r"%2e%2e%2f%2e%2e%2f", "High"),
            (r"\.\./", "Medium"),
            (r"\.\.\\", "Medium"),
            (r"%2e%2e%2f", "Medium"),
        ]
        
        self.command_injection_patterns = [
            (r"sh: .*: command not found", "High"),
            (r"'cmd' is not recognized", "High"),
            (r"root:.*:0:0:", "High"),  # /etc/passwd content
            (r"bin/bash", "Medium"),
            (r"/bin/sh", "Medium"),
        ]
        
        # Sensitive data patterns with better validation
        self.sensitive_data_patterns = [
            (r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b", "Email Address", "Low"),
            (r"\b\d{3}-\d{2}-\d{4}\b", "SSN", "Medium"),
            (r"\b(?:4\d{3}|5[1-5]\d{2}|6011)[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b", "Credit Card Number", "Medium"),
            (r"api[_-]?key[\s:=]+['\"]([a-zA-Z0-9_\-]{20,})['\"]", "API Key", "High"),
            (r"password[\s:=]+['\"]([^\s'\"]{8,})['\"]", "Password", "Medium"),
            (r"bearer\s+[a-zA-Z0-9\-._~+/]{30,}=*", "Bearer Token", "High"),
        ]

    def is_likely_false_positive(self, context: str, vuln_type: str, evidence: str = "") -> bool:
        """Check if a finding is likely a false positive"""
        context_lower = context.lower()
        evidence_lower = evidence.lower() if evidence else ""
        
        # Check test data patterns
        for pattern in self.false_positive_patterns['test_data']:
            if re.search(pattern, evidence_lower, re.IGNORECASE):
                return True
        
        # Check if in JavaScript libraries
        for pattern in self.false_positive_patterns['javascript_libraries']:
            if re.search(pattern, context_lower):
                return True
        
        # Check if in documentation
        for pattern in self.false_positive_patterns['documentation']:
            if re.search(pattern, context_lower):
                return True
        
        # XSS specific checks
        if "XSS" in vuln_type:
            # Likely false positive if in CSS or inline styles
            if re.search(r'<style|\.css|stylesheet', context_lower):
                return True
            # Check if it's just part of legitimate HTML/JS framework code
            if re.search(r'angular\.|ng-|v-bind|@click|react', context_lower):
                return True
        
        # Password field checks - likely false positive if just HTML form
        if "Password" in vuln_type and "password" in evidence_lower:
            if re.search(r'<input.*type.*password|password.*placeholder|enter.*password', context_lower):
                return True
            if evidence_lower in ['password', 'new_password', 'old_password', 'confirm_password']:
                return True
        
        # Email checks - common false positives
        if "Email" in vuln_type and evidence_lower:
            # Short email-like strings are often false positives
            if len(evidence_lower) < 10 or evidence_lower.count('@') > 1:
                return True
        
        # Credit card - check if it's a timestamp or ID (not actual CC)
        if "Credit Card" in vuln_type:
            # Very large numbers are likely JavaScript MAX_SAFE_INTEGER or timestamps
            if evidence and len(evidence.replace('-', '').replace(' ', '')) > 16:
                return True
            # Check for obvious test patterns
            if evidence and re.search(r'1234|0000|9999', evidence):
                return True
        
        return False

    def add_vulnerability(self, vuln_dict: dict):
        """Add vulnerability with false positive checking"""
        # Check confidence level
        confidence = vuln_dict.get("confidence", "Low")
        if self.confidence_levels.get(confidence, 0) < self.confidence_levels.get(self.min_confidence, 0):
            self.false_positive_count += 1
            return  # Skip low confidence findings
        
        # Check for false positives
        context = vuln_dict.get("description", "") + " " + vuln_dict.get("url", "")
        evidence = str(vuln_dict.get("evidence", ""))
        vuln_type = vuln_dict.get("type", "")
        
        if self.is_likely_false_positive(context, vuln_type, evidence):
            self.false_positive_count += 1
            vuln_dict["likely_false_positive"] = True
            # Still add it but mark it
        
        # Deduplicate similar vulnerabilities
        for existing in self.vulnerabilities:
            if (existing.get("type") == vuln_dict.get("type") and 
                existing.get("name") == vuln_dict.get("name") and
                existing.get("url") == vuln_dict.get("url")):
                return  # Duplicate, skip
        
        self.vulnerabilities.append(vuln_dict)

    def detect_file_type(self):
        """Detect if file is XML or binary Burp format"""
        with open(self.state_file_path, 'rb') as f:
            header = f.read(100)
            # Burp binary format - check for common patterns
            if header[:4] == b'fBRP' or header[0:1] == b'f' or self.state_file_path.endswith('.burp'):
                return 'binary'
            # Try to detect XML
            if b'<?xml' in header or b'<items>' in header:
                return 'xml'
        return 'binary' if self.state_file_path.endswith('.burp') else 'unknown'

    def analyze(self):
        """Main analysis method"""
        print(f"[*] Analyzing Burp state file: {self.state_file_path}")
        
        try:
            file_type = self.detect_file_type()
            print(f"[*] Detected file type: {file_type}")
            
            if file_type == 'binary':
                self.analyze_binary_burp_file()
            elif file_type == 'xml':
                self.analyze_xml_file()
            else:
                print("[!] Unknown file format. Please provide either:")
                print("    - Burp Suite project file (.burp)")
                print("    - Burp XML export")
                sys.exit(1)
            
            # Generate report
            self.generate_report()
            
        except FileNotFoundError:
            print(f"[!] File not found: {self.state_file_path}")
            sys.exit(1)
        except Exception as e:
            print(f"[!] Unexpected error: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)

    def analyze_binary_burp_file(self):
        """Analyze binary Burp project file"""
        print("[*] Analyzing binary Burp project file...")
        
        # First, try as SQLite database (newer Burp versions)
        try:
            conn = sqlite3.connect(self.state_file_path)
            cursor = conn.cursor()
            
            # Get all HTTP traffic from request_response table
            try:
                cursor.execute("""
                    SELECT url, method, status, request, response 
                    FROM request_response 
                    WHERE request IS NOT NULL OR response IS NOT NULL
                """)
                
                for row in cursor.fetchall():
                    url, method, status, request, response = row
                    if url:
                        self.analyze_burp_request_response(url, request, response)
                        
            except sqlite3.OperationalError as e:
                print(f"[*] Note: {e}")
            
            # Try to get scanner issues
            try:
                cursor.execute("""
                    SELECT type, severity, confidence, url, detail 
                    FROM scanner_issues
                """)
                
                for row in cursor.fetchall():
                    issue_type, severity, confidence, url, detail = row
                    self.vulnerabilities.append({
                        "type": "Scanner Finding",
                        "severity": severity or "Medium",
                        "confidence": confidence or "Certain",
                        "name": issue_type or "Unknown Issue",
                        "url": url,
                        "description": detail or "No description available"
                    })
                    
            except sqlite3.OperationalError:
                pass
            
            conn.close()
            print(f"[*] Analyzed {len(self.urls_analyzed)} unique URLs")
            
        except sqlite3.DatabaseError:
            # Not a SQLite database - try parsing as Java serialization format
            print("[*] File is not SQLite database, attempting text extraction from binary format...")
            self.analyze_java_serialized_burp_file()

    def analyze_java_serialized_burp_file(self):
        """Extract and analyze HTTP traffic from Java serialized Burp state file"""
        print("[*] Extracting HTTP traffic from binary Burp state file...")
        print("[*] Note: This may take a moment for large files...")
        
        with open(self.state_file_path, 'rb') as f:
            data = f.read()
        
        print(f"[*] File size: {len(data) / (1024*1024):.2f} MB")
        
        # Extract printable strings from binary data
        # Look for HTTP request/response patterns
        text = data.decode('latin-1', errors='ignore')
        
        # Extract unique URLs (limit processing)
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+[^\s<>"{}|\\^`\[\].,;:!?\'\)]'
        all_urls = re.findall(url_pattern, text)
        unique_urls = list(set(all_urls))[:1000]  # Limit to first 1000 unique URLs
        
        print(f"[*] Found {len(all_urls)} URL references, analyzing {len(unique_urls)} unique URLs")
        
        # Split text into chunks for more efficient processing
        chunk_size = 100000  # 100KB chunks
        chunks = []
        for i in range(0, len(text), chunk_size):
            chunks.append(text[i:i + chunk_size])
        
        print(f"[*] Processing {len(chunks)} text chunks...")
        
        # Analyze chunks for vulnerability patterns
        for i, chunk in enumerate(chunks):
            if i % 100 == 0 and i > 0:
                print(f"[*] Processed {i}/{len(chunks)} chunks...")
            
            # Check for HTTP responses in chunk
            if 'HTTP/' in chunk and any(pattern in chunk for pattern in ['200 OK', '404', '500', '302', '301']):
                self.analyze_response(f"chunk_{i}", chunk)
        
        # Analyze specific URLs (limit to avoid timeout)
        for i, url in enumerate(unique_urls[:100]):  # Analyze first 100 URLs in detail
            if url not in self.urls_analyzed:
                self.urls_analyzed.add(url)
                
                # Just check for the URL, don't extract context (too slow)
                # The chunk analysis above will catch response patterns
        
        self.urls_analyzed.update(unique_urls)
        print(f"[*] Analyzed {len(self.urls_analyzed)} unique URLs")

    def analyze_burp_request_response(self, url: str, request_blob, response_blob):
        """Analyze request/response from binary Burp file"""
        if url in self.urls_analyzed:
            return
        self.urls_analyzed.add(url)
        
        try:
            # Decompress if needed
            if request_blob:
                try:
                    request = gzip.decompress(request_blob).decode('utf-8', errors='ignore')
                except:
                    request = request_blob.decode('utf-8', errors='ignore') if isinstance(request_blob, bytes) else str(request_blob)
                self.analyze_request(url, request)
            
            if response_blob:
                try:
                    response = gzip.decompress(response_blob).decode('utf-8', errors='ignore')
                except:
                    response = response_blob.decode('utf-8', errors='ignore') if isinstance(response_blob, bytes) else str(response_blob)
                self.analyze_response(url, response)
                
        except Exception as e:
            pass  # Skip problematic entries

    def analyze_xml_file(self):
        """Analyze XML export file"""
        print("[*] Analyzing XML file...")
        
        try:
            tree = ET.parse(self.state_file_path)
            root = tree.getroot()
            
            # Analyze issues found by Burp Scanner
            self.analyze_scanner_issues(root)
            
            # Analyze HTTP traffic
            self.analyze_http_traffic(root)
            
            # Analyze site map
            self.analyze_sitemap(root)
            
        except ET.ParseError as e:
            print(f"[!] Error parsing XML file: {e}")
            sys.exit(1)

    def analyze_scanner_issues(self, root):
        """Analyze Burp Scanner findings"""
        print("[*] Analyzing Scanner Issues...")
        
        issues = root.findall(".//issue")
        for issue in issues:
            vulnerability = {
                "type": "Scanner Finding",
                "severity": self.get_element_text(issue, "severity"),
                "confidence": self.get_element_text(issue, "confidence"),
                "name": self.get_element_text(issue, "name"),
                "host": self.get_element_text(issue, "host"),
                "path": self.get_element_text(issue, "path"),
                "description": self.get_element_text(issue, "issueBackground"),
                "remediation": self.get_element_text(issue, "remediationBackground"),
            }
            self.vulnerabilities.append(vulnerability)

    def analyze_http_traffic(self, root):
        """Analyze HTTP requests and responses for vulnerabilities"""
        print("[*] Analyzing HTTP Traffic...")
        
        items = root.findall(".//item")
        for item in items:
            self.analyze_item(item)

    def analyze_item(self, item):
        """Analyze individual HTTP request/response pair"""
        try:
            # Get URL
            url = self.get_element_text(item, "url")
            if not url or url in self.urls_analyzed:
                return
            self.urls_analyzed.add(url)
            
            # Get request and response
            request_elem = item.find("request")
            response_elem = item.find("response")
            
            if request_elem is not None:
                request = self.decode_base64(request_elem.text)
                self.analyze_request(url, request)
            
            if response_elem is not None:
                response = self.decode_base64(response_elem.text)
                self.analyze_response(url, response)
                
        except Exception as e:
            print(f"[!] Error analyzing item: {e}")

    def analyze_request(self, url: str, request: str):
        """Analyze HTTP request for vulnerabilities"""
        if not request:
            return
            
        # Check for sensitive data in requests
        for pattern, data_type, confidence in self.sensitive_data_patterns:
            matches = re.findall(pattern, request, re.IGNORECASE)
            if matches:
                # Filter out obvious false positives
                filtered_matches = [m for m in matches if not self.is_likely_false_positive(request, data_type, str(m))]
                if filtered_matches:
                    self.add_vulnerability({
                        "type": "Sensitive Data Exposure",
                        "severity": "Medium",
                        "confidence": confidence,
                        "name": f"{data_type} in Request",
                        "url": url,
                        "description": f"Detected {data_type} in HTTP request",
                        "evidence": str(filtered_matches[:3])  # First 3 matches
                    })

    def analyze_response(self, url: str, response: str):
        """Analyze HTTP response for vulnerabilities"""
        if not response:
            return
        
        response_lower = response.lower()
        
        # SQL Injection indicators
        for pattern, confidence in self.sql_injection_patterns:
            if re.search(pattern, response, re.IGNORECASE):
                self.add_vulnerability({
                    "type": "Potential SQL Injection",
                    "severity": "High",
                    "confidence": confidence,
                    "name": "SQL Error Message",
                    "url": url,
                    "description": f"Response contains SQL error messages (Pattern: {pattern})",
                    "pattern": pattern
                })
                break
        
        # XSS indicators
        for pattern, confidence in self.xss_patterns:
            if re.search(pattern, response, re.IGNORECASE):
                # Get context around the match
                match = re.search(pattern, response, re.IGNORECASE)
                if match:
                    start = max(0, match.start() - 100)
                    end = min(len(response), match.end() + 100)
                    context = response[start:end]
                    
                    self.add_vulnerability({
                        "type": "Potential XSS",
                        "severity": "High" if confidence == "High" else "Medium",
                        "confidence": confidence,
                        "name": "XSS Pattern Detected",
                        "url": url,
                        "description": f"Response contains potential XSS payload (Confidence: {confidence})",
                        "pattern": pattern,
                        "context": context[:200]
                    })
                break
        
        # Path Traversal indicators
        for pattern, confidence in self.path_traversal_patterns:
            if re.search(pattern, response, re.IGNORECASE):
                self.add_vulnerability({
                    "type": "Potential Path Traversal",
                    "severity": "High",
                    "confidence": confidence,
                    "name": "Path Traversal Pattern",
                    "url": url,
                    "description": f"Response contains path traversal patterns (Confidence: {confidence})",
                    "pattern": pattern
                })
                break
        
        # Command Injection indicators
        for pattern, confidence in self.command_injection_patterns:
            if re.search(pattern, response, re.IGNORECASE):
                self.add_vulnerability({
                    "type": "Potential Command Injection",
                    "severity": "Critical",
                    "confidence": confidence,
                    "name": "Command Execution Evidence",
                    "url": url,
                    "description": f"Response contains command execution output (Confidence: {confidence})",
                    "pattern": pattern
                })
                break
        
        # Sensitive data in responses
        for pattern, data_type, confidence in self.sensitive_data_patterns:
            matches = re.findall(pattern, response, re.IGNORECASE)
            if matches:
                # Filter false positives
                filtered_matches = [m for m in matches[:10] if not self.is_likely_false_positive(response, data_type, str(m))]
                if filtered_matches:
                    self.add_vulnerability({
                        "type": "Sensitive Data Exposure",
                        "severity": "High",
                        "confidence": confidence,
                        "name": f"{data_type} in Response",
                        "url": url,
                        "description": f"Detected {data_type} in HTTP response",
                        "evidence": str(filtered_matches[:3])
                    })
        
        # Missing security headers
        if "content-type:" in response_lower and "text/html" in response_lower:
            headers = response.split('\r\n\r\n')[0] if '\r\n\r\n' in response else response
            headers_lower = headers.lower()
            
            if "x-frame-options:" not in headers_lower:
                self.add_vulnerability({
                    "type": "Missing Security Header",
                    "severity": "Medium",
                    "confidence": "Certain",
                    "name": "Missing X-Frame-Options",
                    "url": url,
                    "description": "Response missing X-Frame-Options header (Clickjacking risk)"
                })
            
            if "x-content-type-options:" not in headers_lower:
                self.add_vulnerability({
                    "type": "Missing Security Header",
                    "severity": "Low",
                    "confidence": "Certain",
                    "name": "Missing X-Content-Type-Options",
                    "url": url,
                    "description": "Response missing X-Content-Type-Options header"
                })
            
            if "strict-transport-security:" not in headers_lower and url.startswith("https"):
                self.add_vulnerability({
                    "type": "Missing Security Header",
                    "severity": "Medium",
                    "confidence": "Certain",
                    "name": "Missing HSTS Header",
                    "url": url,
                    "description": "HTTPS response missing Strict-Transport-Security header"
                })
            
            if "content-security-policy:" not in headers_lower:
                self.add_vulnerability({
                    "type": "Missing Security Header",
                    "severity": "Medium",
                    "confidence": "Certain",
                    "name": "Missing CSP Header",
                    "url": url,
                    "description": "Response missing Content-Security-Policy header"
                })

    def analyze_sitemap(self, root):
        """Analyze site map for structural issues"""
        print("[*] Analyzing Site Map...")
        
        # Look for interesting endpoints
        items = root.findall(".//item")
        endpoints = set()
        
        for item in items:
            url = self.get_element_text(item, "url")
            if url:
                endpoints.add(url)
                parsed = urlparse(url)
                
                # Check for admin/debug endpoints
                if re.search(r"/(admin|debug|test|dev|staging|backup|old)", parsed.path, re.IGNORECASE):
                    self.add_vulnerability({
                        "type": "Potentially Sensitive Endpoint",
                        "severity": "Medium",
                        "confidence": "Medium",
                        "name": "Sensitive Endpoint Exposed",
                        "url": url,
                        "description": "Detected potentially sensitive endpoint"
                    })
                
                # Check for backup files
                if re.search(r"\.(bak|old|backup|zip|tar|gz|sql|log)$", parsed.path, re.IGNORECASE):
                    self.add_vulnerability({
                        "type": "Backup File Exposed",
                        "severity": "High",
                        "confidence": "High",
                        "name": "Backup File Accessible",
                        "url": url,
                        "description": "Detected accessible backup or log file"
                    })

    def generate_report(self):
        """Generate vulnerability report"""
        print("\n" + "="*80)
        print("VULNERABILITY ANALYSIS REPORT")
        print("="*80)
        
        if not self.vulnerabilities:
            print("\n[+] No vulnerabilities detected!")
            return
        
        # Count by severity
        severity_count = {"Critical": 0, "High": 0, "Medium": 0, "Low": 0, "Information": 0}
        false_positive_marked = 0
        for vuln in self.vulnerabilities:
            severity = vuln.get("severity", "Information")
            severity_count[severity] = severity_count.get(severity, 0) + 1
            if vuln.get("likely_false_positive"):
                false_positive_marked += 1
        
        print(f"\n[*] Total Vulnerabilities Found: {len(self.vulnerabilities)}")
        print(f"    - Critical: {severity_count['Critical']}")
        print(f"    - High: {severity_count['High']}")
        print(f"    - Medium: {severity_count['Medium']}")
        print(f"    - Low: {severity_count['Low']}")
        print(f"    - Information: {severity_count['Information']}")
        
        # False positive information
        print(f"\n[*] Minimum Confidence Level: {self.min_confidence}")
        print(f"[*] Findings Filtered (Low Confidence): {self.false_positive_count}")
        if false_positive_marked > 0:
            print(f"[*] Findings Marked as Likely False Positives: {false_positive_marked}")
            print(f"    (These are included but flagged for manual review)")
        
        # Group by type
        by_type = {}
        for vuln in self.vulnerabilities:
            vuln_type = vuln.get("type", "Unknown")
            if vuln_type not in by_type:
                by_type[vuln_type] = []
            by_type[vuln_type].append(vuln)
        
        print("\n" + "-"*80)
        print("DETAILED FINDINGS")
        print("-"*80)
        
        for vuln_type, vulns in sorted(by_type.items()):
            print(f"\n[{vuln_type}] - {len(vulns)} instance(s)")
            print("-"*80)
            
            for i, vuln in enumerate(vulns[:10], 1):  # Show first 10 of each type
                print(f"\n  {i}. {vuln.get('name', 'N/A')}")
                print(f"     Severity: {vuln.get('severity', 'N/A')}")
                if "url" in vuln:
                    print(f"     URL: {vuln['url']}")
                if "host" in vuln and "path" in vuln:
                    print(f"     Location: {vuln['host']}{vuln['path']}")
                if "description" in vuln:
                    desc = vuln['description'][:200]
                    print(f"     Description: {desc}...")
                if "evidence" in vuln:
                    print(f"     Evidence: {vuln['evidence']}")
            
            if len(vulns) > 10:
                print(f"\n  ... and {len(vulns) - 10} more instances")
        
        # Save to JSON
        output_file = self.state_file_path.replace(".xml", "_vulnerabilities.json").replace(".burp", "_vulnerabilities.json")
        with open(output_file, 'w') as f:
            json.dump(self.vulnerabilities, f, indent=2)
        print(f"\n[+] Full report saved to: {output_file}")
        
        # Generate summary report
        self.generate_summary_report(severity_count, by_type, output_file)

    def generate_summary_report(self, severity_count, by_type, json_report_path):
        """Generate a concise summary report file"""
        summary_file = self.state_file_path.replace(".xml", "_SUMMARY.txt").replace(".burp", "_SUMMARY.txt")
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("BURP SUITE VULNERABILITY ANALYSIS - EXECUTIVE SUMMARY\n")
            f.write("="*80 + "\n\n")
            
            # File information
            f.write(f"Analyzed File: {self.state_file_path}\n")
            from datetime import datetime
            f.write(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Total URLs Analyzed: {len(self.urls_analyzed)}\n\n")
            
            # Overall Risk Assessment
            f.write("="*80 + "\n")
            f.write("OVERALL RISK ASSESSMENT\n")
            f.write("="*80 + "\n\n")
            
            total_vulns = len(self.vulnerabilities)
            f.write(f"Total Vulnerabilities Found: {total_vulns}\n\n")
            
            # Risk level determination
            if severity_count['Critical'] > 0 or severity_count['High'] > 10:
                risk_level = "CRITICAL"
                risk_color = "ðŸ”´"
            elif severity_count['High'] > 0 or severity_count['Medium'] > 20:
                risk_level = "HIGH"
                risk_color = "ðŸŸ "
            elif severity_count['Medium'] > 0:
                risk_level = "MEDIUM"
                risk_color = "ðŸŸ¡"
            else:
                risk_level = "LOW"
                risk_color = "ðŸŸ¢"
            
            f.write(f"Overall Risk Level: {risk_color} {risk_level}\n\n")
            
            # Severity Breakdown
            f.write("-"*80 + "\n")
            f.write("SEVERITY BREAKDOWN\n")
            f.write("-"*80 + "\n\n")
            f.write(f"  Critical Severity:     {severity_count['Critical']:>5} vulnerabilities\n")
            f.write(f"  High Severity:         {severity_count['High']:>5} vulnerabilities\n")
            f.write(f"  Medium Severity:       {severity_count['Medium']:>5} vulnerabilities\n")
            f.write(f"  Low Severity:          {severity_count['Low']:>5} vulnerabilities\n")
            f.write(f"  Informational:         {severity_count['Information']:>5} vulnerabilities\n\n")
            
            # Top Vulnerability Types
            f.write("="*80 + "\n")
            f.write("TOP VULNERABILITY CATEGORIES\n")
            f.write("="*80 + "\n\n")
            
            sorted_types = sorted(by_type.items(), key=lambda x: len(x[1]), reverse=True)
            for i, (vuln_type, vulns) in enumerate(sorted_types[:10], 1):
                # Count severity distribution for this type
                type_severity = {"Critical": 0, "High": 0, "Medium": 0, "Low": 0}
                for v in vulns:
                    sev = v.get("severity", "Low")
                    if sev in type_severity:
                        type_severity[sev] += 1
                
                f.write(f"{i}. {vuln_type}\n")
                f.write(f"   Total Instances: {len(vulns)}\n")
                f.write(f"   Severity Distribution: ")
                f.write(f"Critical={type_severity['Critical']}, High={type_severity['High']}, ")
                f.write(f"Medium={type_severity['Medium']}, Low={type_severity['Low']}\n\n")
            
            # Key Findings
            f.write("="*80 + "\n")
            f.write("KEY FINDINGS & CRITICAL ISSUES\n")
            f.write("="*80 + "\n\n")
            
            # Highlight critical and high severity issues
            critical_issues = [v for v in self.vulnerabilities if v.get("severity") in ["Critical", "High"]]
            if critical_issues:
                # Group by type
                critical_by_type = {}
                for v in critical_issues:
                    vtype = v.get("type", "Unknown")
                    if vtype not in critical_by_type:
                        critical_by_type[vtype] = []
                    critical_by_type[vtype].append(v)
                
                for vuln_type, vulns in sorted(critical_by_type.items(), key=lambda x: len(x[1]), reverse=True)[:5]:
                    f.write(f"â€¢ {vuln_type}: {len(vulns)} instances\n")
                    # Show a sample
                    sample = vulns[0]
                    f.write(f"  Example: {sample.get('name', 'N/A')}\n")
                    if 'url' in sample and not sample['url'].startswith('chunk_'):
                        f.write(f"  URL: {sample['url'][:100]}...\n" if len(sample['url']) > 100 else f"  URL: {sample['url']}\n")
                    f.write(f"  Description: {sample.get('description', 'N/A')[:150]}...\n\n")
            else:
                f.write("No critical or high severity issues found.\n\n")
            
            # Recommendations
            f.write("="*80 + "\n")
            f.write("RECOMMENDATIONS\n")
            f.write("="*80 + "\n\n")
            
            recommendations = []
            
            if "Potential SQL Injection" in by_type:
                recommendations.append(
                    "1. SQL Injection: Implement parameterized queries and input validation.\n"
                    "   Use prepared statements and ORM frameworks to prevent SQL injection attacks.\n"
                )
            
            if "Potential XSS" in by_type:
                recommendations.append(
                    "2. Cross-Site Scripting (XSS): Implement proper output encoding and CSP headers.\n"
                    "   Sanitize all user input and use context-aware encoding.\n"
                )
            
            if "Missing Security Header" in by_type:
                recommendations.append(
                    "3. Security Headers: Add missing security headers to all HTTP responses:\n"
                    "   - X-Frame-Options: DENY or SAMEORIGIN\n"
                    "   - X-Content-Type-Options: nosniff\n"
                    "   - Content-Security-Policy: Implement a strict CSP\n"
                    "   - Strict-Transport-Security: max-age=31536000; includeSubDomains\n"
                )
            
            if "Sensitive Data Exposure" in by_type:
                recommendations.append(
                    "4. Sensitive Data: Remove or properly protect sensitive information:\n"
                    "   - Never expose credentials, API keys, or tokens in responses\n"
                    "   - Implement proper data masking for PII and payment information\n"
                    "   - Use secure session management and encryption\n"
                )
            
            if "Potential Path Traversal" in by_type:
                recommendations.append(
                    "5. Path Traversal: Validate and sanitize all file path inputs:\n"
                    "   - Use allowlists for permitted files/directories\n"
                    "   - Implement proper access controls\n"
                    "   - Avoid direct file path manipulation from user input\n"
                )
            
            if "Potential Command Injection" in by_type:
                recommendations.append(
                    "6. Command Injection: Avoid executing system commands with user input:\n"
                    "   - Use safe APIs instead of shell commands\n"
                    "   - Implement strict input validation and sanitization\n"
                    "   - Run with least privilege principles\n"
                )
            
            if recommendations:
                for rec in recommendations:
                    f.write(rec + "\n")
            else:
                f.write("Continue following security best practices and regular testing.\n\n")
            
            # Next Steps
            f.write("="*80 + "\n")
            f.write("NEXT STEPS\n")
            f.write("="*80 + "\n\n")
            f.write("1. Review the detailed JSON report for complete vulnerability information\n")
            f.write("2. Prioritize remediation based on severity (Critical > High > Medium > Low)\n")
            f.write("3. Verify each finding manually to eliminate false positives\n")
            f.write("4. Implement security fixes and retest affected areas\n")
            f.write("5. Conduct a follow-up security assessment after remediation\n")
            f.write("6. Consider implementing automated security testing in CI/CD pipeline\n\n")
            
            # Conclusion
            f.write("="*80 + "\n")
            f.write("CONCLUSION\n")
            f.write("="*80 + "\n\n")
            
            if total_vulns == 0:
                f.write("No vulnerabilities were detected in the analyzed Burp state file.\n")
                f.write("Continue maintaining good security practices.\n")
            elif severity_count['Critical'] > 0 or severity_count['High'] > 20:
                f.write(f"The analysis identified {total_vulns} vulnerabilities, including ")
                f.write(f"{severity_count['Critical']} Critical and {severity_count['High']} High severity issues.\n\n")
                f.write("IMMEDIATE ACTION REQUIRED: These vulnerabilities pose significant security risks\n")
                f.write("and should be addressed as a priority. Focus on the Critical and High severity\n")
                f.write("issues first, particularly SQL Injection, XSS, and Command Injection vulnerabilities.\n")
            elif severity_count['High'] > 0:
                f.write(f"The analysis identified {total_vulns} vulnerabilities, including ")
                f.write(f"{severity_count['High']} High severity issues.\n\n")
                f.write("ACTION RECOMMENDED: Address the High severity vulnerabilities promptly to\n")
                f.write("reduce security risks. Review and implement the recommendations provided.\n")
            else:
                f.write(f"The analysis identified {total_vulns} vulnerabilities of Medium or Low severity.\n\n")
                f.write("While no critical issues were found, it's recommended to address the identified\n")
                f.write("vulnerabilities to improve overall security posture, particularly the missing\n")
                f.write("security headers and any data exposure issues.\n")
            
            f.write("\n" + "="*80 + "\n")
            f.write(f"For detailed findings, see: {json_report_path}\n")
            f.write("="*80 + "\n")
        
        print(f"[+] Summary report saved to: {summary_file}")

    @staticmethod
    def get_element_text(parent, tag):
        """Safely get text from XML element"""
        elem = parent.find(tag)
        return elem.text if elem is not None and elem.text else ""

    @staticmethod
    def decode_base64(data):
        """Decode base64 encoded data"""
        try:
            if data:
                decoded = base64.b64decode(data)
                return decoded.decode('utf-8', errors='ignore')
        except Exception:
            pass
        return ""


def main():
    if len(sys.argv) < 2:
        print("Burp Suite Vulnerability Analyzer")
        print("=" * 80)
        print("\nUsage: python burp_vulnerability_analyzer.py <burp_file> [--confidence LEVEL]")
        print("\nArguments:")
        print("  burp_file          Path to Burp Suite project file (.burp) or XML export")
        print("\nOptions:")
        print("  --confidence LEVEL Set minimum confidence level: Low, Medium, High, Certain")
        print("                     Default: Low (show all findings)")
        print("                     Higher levels reduce false positives but may miss issues")
        print("\nExamples:")
        print("  python burp_vulnerability_analyzer.py scan.burp")
        print("  python burp_vulnerability_analyzer.py scan.burp --confidence Medium")
        print("  python burp_vulnerability_analyzer.py export.xml --confidence High")
        print("\nOutput:")
        print("  - JSON report with all findings")
        print("  - Text summary with executive overview")
        print("  - False positive filtering and confidence scoring")
        sys.exit(1)
    
    state_file = sys.argv[1]
    
    # Parse confidence level
    min_confidence = "Low"
    if len(sys.argv) >= 4 and sys.argv[2] == "--confidence":
        confidence_arg = sys.argv[3]
        if confidence_arg in ["Low", "Medium", "High", "Certain"]:
            min_confidence = confidence_arg
        else:
            print(f"[!] Invalid confidence level: {confidence_arg}")
            print("[!] Valid options: Low, Medium, High, Certain")
            sys.exit(1)
    
    analyzer = BurpVulnerabilityAnalyzer(state_file, min_confidence=min_confidence)
    analyzer.analyze()


if __name__ == "__main__":
    main()
